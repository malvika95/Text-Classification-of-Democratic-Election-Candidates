{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text As Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import glob\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. To begin, you will ﬁrst work through processing the data. Start by loading in the training data and test data. Keep each in their own dataframe/list (i.e. a dataframe/list for all training observation text and a separate one for all test observations). How many training and test observations do you have?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : There are 528 training observations and 111 Test observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the training dataset is  528\n"
     ]
    }
   ],
   "source": [
    "#Loading training data as a dataframe\n",
    "train_file = os.listdir('./train')\n",
    "\n",
    "#Storing the file name,speaker name and quote in the dataframe\n",
    "train_df = pd.DataFrame(columns=['FileName','Speaker','Quote'])\n",
    "for file in train_file :\n",
    "    file_name = file.split(\"_\")[0]\n",
    "    file_data = open('./train/'+file,'r',encoding='UTF-8')\n",
    "    data = file_data.readline()\n",
    "    speaker = data.split(\":\")[0]\n",
    "    quote = data[data.find(\":\")+1:]\n",
    "    train_df=train_df.append({'FileName': file_name,'Speaker': speaker,'Quote':quote},ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"Number of records in the training dataset is \", len(train_df))\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the test dataset is  111\n"
     ]
    }
   ],
   "source": [
    "#Loading test data directory\n",
    "test_file = sorted(os.listdir('./test'))\n",
    "#Storing the  quote in the list\n",
    "test_data = pd.DataFrame()\n",
    "for file in test_file :\n",
    "    file_data = open('./test/'+file,'r',encoding='UTF-8')\n",
    "    data = file_data.readline()\n",
    "    seq = int((file.split('_')[1]).split('.')[0])\n",
    "    test_data = test_data.append({'FileName':file,'Quote':data,'Seq':seq},ignore_index=True)\n",
    "    \n",
    "print(\"Number of records in the test dataset is \", len(test_data))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create a vector of training labels. These labels can be found in one of two ways: in the ﬁle name of each training data observation and at the beginning of the text for each training ﬁle. The test data will not have the labels at the beginning of the text so remove these labels from your training observations. Are there any instances where the name of the ﬁle does not align with the name at the start of the text? If so, how many such observations are there? Exclude these from your training data. What does the distribution of labels look like? Comment on what you see.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We can see that there are no instances where the name of the file does not align with the name of the start of the text. On plotting a histogram to examine the distribution of the class labels we can see there is an imbalance between the number of observations for each class.We can see that the class Warren has 80 observations,Sanders and Biden have 60 observations while the classes Gabbard and Steyer have only 16 and 19 observations respectively. This is less or equal to 1/4th of the observations in the majority class (Warren).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of instances where the name of the file does not align with the name at the start of the text are  0\n"
     ]
    }
   ],
   "source": [
    "#Creating a vector of the file names as the training labels\n",
    "training_label = np.array(train_df.iloc[:,0])\n",
    "\n",
    "#Checking if there are instances where the file name does not concide with the speaker name in the file\n",
    "check=[]\n",
    "\n",
    "#Extracting the surname of the speaker to compare with the file name\n",
    "train_df['speaker_surname'] = train_df['Speaker'].apply(lambda x:x.split(' ')[1])\n",
    "\n",
    "#Comparing the rows where file name is same as the beginning of the text\n",
    "check = np.where(train_df.FileName==train_df.speaker_surname, True, False)\n",
    "\n",
    "print(\"The number of instances where the name of the file does not align with the name at the start of the text are \",list(check).count(False))\n",
    "\n",
    "#Storing only the quotes in the training set that will be used in for our modelling\n",
    "train_data = train_df.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Biden': 60,\n",
       "         'Booker': 50,\n",
       "         'Buttigieg': 60,\n",
       "         'Castro': 23,\n",
       "         'Gabbard': 16,\n",
       "         'Harris': 40,\n",
       "         'Klobuchar': 55,\n",
       "         \"O'Rourke\": 33,\n",
       "         'Sanders': 60,\n",
       "         'Steyer': 19,\n",
       "         'Warren': 80,\n",
       "         'Yang': 32})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr8AAAFlCAYAAADiVIA6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de7zl93zv8ddbRkQSkURGGonpRE9QHIKRIj0OgoOUpBW3ukw0TE8vFO1helNtVcdpi6KOxnUoEUIkRJGmiRRpYnKRK0KMSBPJIFFBSuJz/vh9t6zZ9p59W2su+b6ej8d+7N/vt36X73f9Luu9vr/vWitVhSRJktSD223rAkiSJElbi+FXkiRJ3TD8SpIkqRuGX0mSJHXD8CtJkqRuGH4lSZLUjWVbc2P77LNPrVy5cmtuUpIkSZ0599xzv1VVy2d6bKuG35UrV7Jhw4atuUlJkiR1JsnXZ3vMbg+SJEnqhuFXkiRJ3TD8SpIkqRuGX0mSJHXD8CtJkqRuGH4lSZLUDcOvJEmSumH4lSRJUjcMv5IkSeqG4VeSJEndmFf4TfKSJJckuTjJcUl2SXJgkrOTXJ7k+CQ7T7qwkiRJ0lLMGX6T7A+8CFhVVfcDdgKeAbwGeF1VHQRcDxwzyYJKkiRJSzXfbg/LgDsmWQbsClwDPBo4oT2+Hjhy/MWTJEmSxmfZXDNU1X8k+VvgSuCHwKeAc4EbqurmNttVwP4zLZ9kDbAGYMWKFeMosyRJ0ja3cu0pE13/xnWHT3T9vZpPt4e9gCOAA4G7AbsBT5hh1ppp+ao6tqpWVdWq5cuXL6WskiRJ0pLMp9vDY4CvVdWmqvox8GHg4cCerRsEwAHA1RMqoyRJkjQW8wm/VwIPTbJrkgCHAZcCpwNHtXlWAydNpoiSJEnSeMwZfqvqbIYPtp0HXNSWORZ4OfDSJF8B7gK8fYLllCRJkpZszg+8AVTVnwF/Nm3yFcAhYy+RJEmSNCH+wpskSZK6YfiVJElSNwy/kiRJ6obhV5IkSd0w/EqSJKkbhl9JkiR1w/ArSZKkbhh+JUmS1A3DryRJkrph+JUkSVI3DL+SJEnqhuFXkiRJ3TD8SpIkqRuGX0mSJHXD8CtJkqRuGH4lSZLUDcOvJEmSumH4lSRJUjcMv5IkSeqG4VeSJEndMPxKkiSpG4ZfSZIkdcPwK0mSpG4YfiVJktQNw68kSZK6YfiVJElSNwy/kiRJ6obhV5IkSd0w/EqSJKkbhl9JkiR1Y87wm+ReSS4Y+fvPJC9OsneSU5Nc3v7vtTUKLEmSJC3WnOG3qr5UVQdX1cHAg4EfACcCa4HTquog4LQ2LkmSJG23Ftrt4TDgq1X1deAIYH2bvh44cpwFkyRJksZtoeH3GcBxbXjfqroGoP2/60wLJFmTZEOSDZs2bVp8SSVJkqQlmnf4TbIz8GTggwvZQFUdW1WrqmrV8uXLF1o+SZIkaWwW0vL7BOC8qrq2jV+bZD+A9v+6cRdOkiRJGqeFhN9ncmuXB4CTgdVteDVw0rgKJUmSJE3CvMJvkl2BxwIfHpm8DnhsksvbY+vGXzxJkiRpfJbNZ6aq+gFwl2nTvs3w7Q+SJEnSDsFfeJMkSVI3DL+SJEnqhuFXkiRJ3TD8SpIkqRuGX0mSJHXD8CtJkqRuGH4lSZLUDcOvJEmSumH4lSRJUjcMv5IkSeqG4VeSJEndMPxKkiSpG4ZfSZIkdcPwK0mSpG4YfiVJktQNw68kSZK6YfiVJElSNwy/kiRJ6obhV5IkSd0w/EqSJKkbhl9JkiR1w/ArSZKkbhh+JUmS1A3DryRJkrph+JUkSVI3DL+SJEnqhuFXkiRJ3TD8SpIkqRuGX0mSJHVjXuE3yZ5JTkjyxSSXJXlYkr2TnJrk8vZ/r0kXVpIkSVqK+bb8/j3wiaq6N/AA4DJgLXBaVR0EnNbGJUmSpO3WnOE3yR7AI4C3A1TVj6rqBuAIYH2bbT1w5KQKKUmSJI3DfFp+7wFsAt6Z5Pwkb0uyG7BvVV0D0P7fdYLllCRJkpZs2TzneRDwwqo6O8nfs4AuDknWAGsAVqxYsahCLtXKtadMfBsb1x0+8W3s6Ca9H9wHknriNVVanPm0/F4FXFVVZ7fxExjC8LVJ9gNo/6+baeGqOraqVlXVquXLl4+jzJIkSdKizBl+q+qbwDeS3KtNOgy4FDgZWN2mrQZOmkgJJUmSpDGZT7cHgBcC702yM3AF8DyG4PyBJMcAVwJPnUwRJUmSpPGYV/itqguAVTM8dNh4iyNJkiRNjr/wJkmSpG4YfiVJktQNw68kSZK6YfiVJElSNwy/kiRJ6obhV5IkSd0w/EqSJKkbhl9JkiR1w/ArSZKkbhh+JUmS1A3DryRJkrph+JUkSVI3DL+SJEnqhuFXkiRJ3Vi2rQsgSRqvlWtPmej6N647fKLrl6RJsuVXkiRJ3TD8SpIkqRuGX0mSJHXD8CtJkqRuGH4lSZLUDcOvJEmSumH4lSRJUjcMv5IkSeqG4VeSJEndMPxKkiSpG4ZfSZIkdcPwK0mSpG4YfiVJktQNw68kSZK6YfiVJElSN5bNZ6YkG4HvAbcAN1fVqiR7A8cDK4GNwNOq6vrJFFOSJElauoW0/D6qqg6uqlVtfC1wWlUdBJzWxiVJkqTt1lK6PRwBrG/D64Ejl14cSZIkaXLmG34L+FSSc5OsadP2raprANr/u06igJIkSdK4zKvPL3BoVV2d5K7AqUm+ON8NtLC8BmDFihWLKKIAVq49ZaLr37ju8ImuX5IkaXswr5bfqrq6/b8OOBE4BLg2yX4A7f91syx7bFWtqqpVy5cvH0+pJUmSpEWYM/wm2S3JnaaGgccBFwMnA6vbbKuBkyZVSEmSJGkc5tPtYV/gxCRT87+vqj6R5PPAB5IcA1wJPHVyxZQkSZKWbs7wW1VXAA+YYfq3gcMmUShJkiRpEvyFN0mSJHXD8CtJkqRuGH4lSZLUDcOvJEmSumH4lSRJUjcMv5IkSeqG4VeSJEndMPxKkiSpG4ZfSZIkdcPwK0mSpG4YfiVJktQNw68kSZK6YfiVJElSNwy/kiRJ6obhV5IkSd0w/EqSJKkbhl9JkiR1w/ArSZKkbhh+JUmS1A3DryRJkrph+JUkSVI3DL+SJEnqhuFXkiRJ3TD8SpIkqRuGX0mSJHXD8CtJkqRuGH4lSZLUDcOvJEmSumH4lSRJUjcMv5IkSerGvMNvkp2SnJ/kY238wCRnJ7k8yfFJdp5cMSVJkqSlW0jL7+8Bl42MvwZ4XVUdBFwPHDPOgkmSJEnjNq/wm+QA4HDgbW08wKOBE9os64EjJ1FASZIkaVyWzXO+1wMvA+7Uxu8C3FBVN7fxq4D9Z1owyRpgDcCKFSsWX1JJ2gpWrj1louvfuO7wia5fkrRlc7b8JvkV4LqqOnd08gyz1kzLV9WxVbWqqlYtX758kcWUJEmSlm4+Lb+HAk9O8kRgF2APhpbgPZMsa62/BwBXT66YkiRJ0tLN2fJbVX9YVQdU1UrgGcC/VtWzgNOBo9psq4GTJlZKSZIkaQyW8j2/LwdemuQrDH2A3z6eIkmSJEmTMd8PvAFQVWcAZ7ThK4BDxl8kSZIkaTL8hTdJkiR1w/ArSZKkbhh+JUmS1A3DryRJkrph+JUkSVI3DL+SJEnqhuFXkiRJ3TD8SpIkqRuGX0mSJHXD8CtJkqRuGH4lSZLUDcOvJEmSumH4lSRJUjcMv5IkSeqG4VeSJEndMPxKkiSpG4ZfSZIkdcPwK0mSpG4YfiVJktQNw68kSZK6YfiVJElSNwy/kiRJ6saybV0ASZJGrVx7ysS3sXHd4RPfhqTtky2/kiRJ6obhV5IkSd0w/EqSJKkb9vmVJEnq1KT72G+P/ett+ZUkSVI3DL+SJEnqhuFXkiRJ3Zgz/CbZJck5Sb6Q5JIkf96mH5jk7CSXJzk+yc6TL64kSZK0ePNp+f0v4NFV9QDgYODxSR4KvAZ4XVUdBFwPHDO5YkqSJElLN2f4rcGNbfT27a+ARwMntOnrgSMnUkJJkiRpTObV5zfJTkkuAK4DTgW+CtxQVTe3Wa4C9p9l2TVJNiTZsGnTpnGUWZIkSVqUeYXfqrqlqg4GDgAOAX5xptlmWfbYqlpVVauWL1+++JJKkiRJS7Sgb3uoqhuAM4CHAnsmmfqRjAOAq8dbNEmSJGm85vNtD8uT7NmG7wg8BrgMOB04qs22GjhpUoWUJEmSxmE+P2+8H7A+yU4MYfkDVfWxJJcC70/yKuB84O0TLKckSZK0ZHOG36q6EHjgDNOvYOj/K0mSJO0Q/IU3SZIkdcPwK0mSpG4YfiVJktQNw68kSZK6YfiVJElSNwy/kiRJ6obhV5IkSd0w/EqSJKkbhl9JkiR1w/ArSZKkbhh+JUmS1A3DryRJkrph+JUkSVI3DL+SJEnqhuFXkiRJ3TD8SpIkqRuGX0mSJHXD8CtJkqRuGH4lSZLUDcOvJEmSumH4lSRJUjeWbesCSDuKlWtPmfg2Nq47fOLbkCSpZ7b8SpIkqRuGX0mSJHXD8CtJkqRuGH4lSZLUDcOvJEmSumH4lSRJUjcMv5IkSeqG4VeSJEndmDP8Jrl7ktOTXJbkkiS/16bvneTUJJe3/3tNvriSJEnS4s2n5fdm4Per6heBhwK/k+Q+wFrgtKo6CDitjUuSJEnbrTnDb1VdU1XnteHvAZcB+wNHAOvbbOuBIydVSEmSJGkcFtTnN8lK4IHA2cC+VXUNDAEZuOssy6xJsiHJhk2bNi2ttJIkSdISzDv8Jtkd+BDw4qr6z/kuV1XHVtWqqlq1fPnyxZRRkiRJGot5hd8kt2cIvu+tqg+3ydcm2a89vh9w3WSKKEmSJI3HfL7tIcDbgcuq6rUjD50MrG7Dq4GTxl88SZIkaXyWzWOeQ4HnABcluaBN+yNgHfCBJMcAVwJPnUwRJUnSbc3KtadMfBsb1x0+8W1oxzNn+K2qzwCZ5eHDxlscSZIkaXL8hTdJkiR1w/ArSZKkbhh+JUmS1A3DryRJkrph+JUkSVI3DL+SJEnqhuFXkiRJ3TD8SpIkqRuGX0mSJHXD8CtJkqRuzPnzxpI0XyvXnjLxbWxcd/jEtyFJuu2y5VeSJEndMPxKkiSpG4ZfSZIkdcPwK0mSpG4YfiVJktQNw68kSZK6YfiVJElSNwy/kiRJ6obhV5IkSd0w/EqSJKkbhl9JkiR1w/ArSZKkbhh+JUmS1A3DryRJkrph+JUkSVI3DL+SJEnqhuFXkiRJ3TD8SpIkqRuGX0mSJHVjzvCb5B1Jrkty8ci0vZOcmuTy9n+vyRZTkiRJWrr5tPy+C3j8tGlrgdOq6iDgtDYuSZIkbdfmDL9VdSbwnWmTjwDWt+H1wJFjLpckSZI0dovt87tvVV0D0P7fdbYZk6xJsiHJhk2bNi1yc5IkSdLSTfwDb1V1bFWtqqpVy5cvn/TmJEmSpFktNvxem2Q/gPb/uvEVSZIkSZqMxYbfk4HVbXg1cNJ4iiNJkiRNzny+6uw44CzgXkmuSnIMsA54bJLLgce2cUmSJGm7tmyuGarqmbM8dNiYyyJJkiRNlL/wJkmSpG4YfiVJktQNw68kSZK6YfiVJElSNwy/kiRJ6obhV5IkSd0w/EqSJKkbhl9JkiR1w/ArSZKkbhh+JUmS1A3DryRJkrph+JUkSVI3DL+SJEnqhuFXkiRJ3TD8SpIkqRuGX0mSJHXD8CtJkqRuGH4lSZLUDcOvJEmSumH4lSRJUjcMv5IkSeqG4VeSJEndMPxKkiSpG4ZfSZIkdcPwK0mSpG4YfiVJktQNw68kSZK6YfiVJElSNwy/kiRJ6saSwm+Sxyf5UpKvJFk7rkJJkiRJk7Do8JtkJ+AfgCcA9wGemeQ+4yqYJEmSNG5Lafk9BPhKVV1RVT8C3g8cMZ5iSZIkSeO3lPC7P/CNkfGr2jRJkiRpu5SqWtyCyVOB/1VVz2/jzwEOqaoXTptvDbCmjd4L+NLii7to+wDf2gbb3Vpuy/Wzbjuu23L9rNuO67ZcP+u247ot129b1e3nq2r5TA8sW8JKrwLuPjJ+AHD19Jmq6ljg2CVsZ8mSbKiqVduyDJN0W66fddtx3ZbrZ912XLfl+lm3HddtuX7bY92W0u3h88BBSQ5MsjPwDODk8RRLkiRJGr9Ft/xW1c1Jfhf4JLAT8I6qumRsJZMkSZLGbCndHqiqjwMfH1NZJmmbdrvYCm7L9bNuO67bcv2s247rtlw/67bjui3Xb7ur26I/8CZJkiTtaPx5Y0mSJHVjhwu/SW5JckGSLyQ5L8nD2/S7JTlhlmXOSLJdfdJwymz1WcR6HpnkY+Mu3wK2v+B6JHlxkl1Hxv9o2uOfm8c63ratf1kwyc8leX+Srya5NMnHk9xzgevY7LnYFpLsm+R9Sa5Icm6Ss5L86hbmn/WYS3LjmMu2Mck+41xnW++N08aPTvKmJa5z1mvROIyWOckTk1yeZEWSVyb5gzmWHcu1MMm7khy11PXMsY0DkpzU6vfVJH+fZOd23L2rzXN0kk3t2vPFJC8Z4/ZXJrl4XOvbwnb+OMklSS5s9filMaxze37N+5n6bg/Xv8VK8rokLx4Z/2SSt42M/12Sl26b0o1fBp9J8oSRaU9L8oltWa6F2uHCL/DDqjq4qh4A/CHw1wBVdXVVTfRiPCEz1mdrSrKkvt/NYurxYmD0grdZ+K2qOQN0VT2/qi5dUEnHKEmAE4EzquoXquo+DPXYd4Grmv5cjG5jp6WVcm6tHh8Bzqyqe1TVgxm+weWASW97hrKM43jcKqaXNcmyrXUtSnIY8Ebg8VV15aS3Ny7txXOLrz3tePww8JGqOgi4J7A78FczzH58VR0MHAr8cZK7zzDPQss48XOubedhwK8AD6qq+wOPYfMfj9oqtoP6znr9G+O2J1XHzwFTjXC3Y/hO2/uOPP5w4LNzrWSm82Jr7ZeFqKGv7P8GXptklyS7MZyXv7NtS7YwO2L4HbUHcD1s/i49yR1bS9yFSY4H7ji1QJLHtRat85J8MMnubfrGJH/epl+U5N7buD5J8jdJLm7lefqWpo9K8pAk5ye5R5LdkrwjyefbtCPaPEe3+n8U+NQE67FZ62CSN7Vtvwi4G3B6ktOTrAPu2FoC3tvmvbH9v12SN7fWgo9laFk9qj320xaOLezbJ2ZoFfpMkjdkvC3kjwJ+XFVvmZpQVRcA5yc5beR4mnred0tySoYW8ouTPH36czFV9yR/keRs4GFJDmv776K2P+8wxjoAPBr40bR6fL2q3tjOrX9rdZneqr9HkhMztHi/ZfTinaHF47z2PCxv017QjsUvJPlQWmtPhpbE17b6vybJXZJ8qtX5H4GMub5zSvKkJGe3MvxLkn3b9FcmOTbJp4B3Tz+Xpl2L7pvknHZcX5jkoDGV7X8AbwUOr6qvzvD4wUn+vW3zxCR7jTz87CSfa8ffISN1+oOR5S9OsrINP7et5wtJ3jOynke09Vwxcj7uPstxvzLJZUneDJzH5t8RP5NHAzdV1TsBquoW4CXAbwA/Ar47fYGq+jbwFWC/ts2fb2W5sP1f0aZv1mo9cp15ZLsWvQ+4aNrzeY92HDwkyU4ZrsGfb+v+zTnqsiX7Ad+qqv9qdfhWVV2d5BVt/Re3Yy2tHGckeU07pr7cjoOlvOa9IslngKcmeVE7jy9M8v4l1GlB9QWO4mevfz9T5nYNPHGkXo9N8uGF1HFCdfosLfwyhN6Lge8l2SvDdfoXgcvme17kZ6/9D07y6Qx34z6ZZOr4nvFY2Bqq6mLgo8DLgT8D3l1VX03y0VbOS5JM/QDasiQ3JFnXriFnJblre+ygDNfYc5L8ZZIbtlYdqKod6g+4BbgA+CLDBfDBbfpK4OI2/FKGr14DuD9wM7CK4R3ZmcBu7bGXA69owxuBF7bh3wbeto3r8xTgVIavkdsXuJLhwjHb9EcCH2M4Cc8FVrT1vBp4dhveE/gysBtwNMMPlew94Xo8EvjYyHxvAo4eec73GXnsxmnrvLH9P4rhW0VuB/wcQ7A+qj12xpb2LbALQ8vCgW36caPlGUO9XwS8bobpy4A92vA+DC/KafvvrSPz3XmW56KAp7XhqTrcs42/G3jxmI/DGevRHtsV2KUNHwRsGNm3NwH3aMfjqSP7pYBnteFXAG9qw3cZWe+ruPWce1c7fndq42/g1nPz8La+fcZR11mO26m/K0fKuhe3fij4+cDfteFXMpxjd2zjRzNyLrH5teiNI8/DzlPLLLHMPwa+A9x/2vRXAn/Qhi8E/mcb/gvg9SPny1vb8CNGyvnTZdv4xa0e92X4Vc592vSpOr4L+CDDOXkf4CtzHPcrgZ8AD13ieXX+aL3bcz+1v1a0fTh1rH4UWN2Gf4OhFXmq7EeNrGPqOvNI4Pvceq1Y2Z6He7XtHtymrwH+pA3fAdgwtcwi9uXurcxfBt48ss/2HpnnPcCTRvbf1HH4ROBf2vBiX/NeNrKdq4E7tOE9x32uzVHfjSPH2GzX8jC8vixv098HPGkhdZzUX9vOCuA3GVpF/7Ltn0Nb2eZ9XrD5tf/2DC3LU3V++sh+nvFY2Fp/DDniSwxvFKeOm6nrw67ApQzX0GWtTk9oj70WWNuGPwE8tQ3/LnDD1ir/DnN7ccQPa7jFNXUL5d1J7jdtnkcwvHhSVRcmubBNfyjDhfqz7Y30zsBZI8t9uP0/F/i1yRT/Z8xWn18GjquhxePaJJ8GHrKF6f/J8A7zWOBxVTX1a3uPA5480qqzC8NJCnBqVX1nwvUYh18GPlhVPwG+OdU6MM1s+/bewBVV9bU233Hc+nPbkxTg1UkewXBx25/hzcpFwN8meQ1DCP+3WZa/BfhQG74X8LWq+nIbX89wi+n1Eyt88g8Mz/uPGG5NvinJwa1co/2Zz6mqK9oyx7VlTmCo8/Ftnn/i1nPrfklexfBGbHeG7wmf8sF2XMNwDv8aQFWdkuT68dbwp3563LY6HM0QGmDo8nF8a2nZGfjayHInV9UPR8ZnO5fOYrgVfwDw4aq6fAxl/jHDC+IxwO9NfzDJnRnCy6fbpPUMQXXKcQBVdWaSPZLsuYVtPRo4oYYWOqbV8SPtnLw0rVWc2Y97gK9X1b/Ps45heMGcz/SnJ3kUw3nygqq6qU1/GLdex98D/N95bPeckWsFwHLgJOApdev32D8OuP9I6/GdGd4Uji43L1V1Y5IHA/+D4S7S8UnWMrQcvowhROwNXMIQ5mHz16mVbXixr3nHjwxfCLw3yUcYukCN3RbqO2rGMldVZbjz8Owk72TYv88FHj/T/CPrG63jpEy1/j6cIdzt34a/y3CuLuS8mH7tvx9waqvbTsA1I/POdCxsFVX1/XaX4cZqLfnAS5I8uQ0fAPwCw5udH1bVP4+UdaqV+pcYgjsMb2ZeNfmSD3bE8PtTVXVWhg/BzPTbzbNdOE+tqmfOssqpHXgL2+C5mVaf2W7zbun27zUM4faB3PpT02G4cH9ps5UMH6r4/tJKPLNp9biZzbvX7LKIVc7nlveM+zbJAxexvYW4hKFlerpnMdT/wVX14yQbGVqkvtwu/k8E/jrJp6rqL2ZY/qaRILg1bvlfwtAqDUBV/U7bhxsYbjdfCzyAYV/eNLLc9PNstu9OnJr+LuDIqvpCC5qPHJln+vG4rb+H8Y3Aa6vq5CSPZGgdnTK9rDOeS1X1vnb78nDgk0meX1X/usRy/QR4GvAvSf6oql69wOVn2meznaezhVC49Xo5NR/Mcty3xxZyvdnseARIsgdDd4np3TyOr6rfbW+6T0nyz1X1zRnWOVWPn9Y1Q6LYeWSe6WX8LsNdl0NbmWCo6wur6pOMQTvPzwDOSHIRQ+vh/YFVVfWNJK9k8+vmbK9Ti3nNG63v4Qwh+snAnya5b1XdvMDqzGmG+q6eNsuWyvxOhjcBNzG8Wb657cP51nFSpvr9/neGuwXfAH6foVHqHSzsvJh+7b+kqh42y3a3aWZhuBb9BCDJYxiOn4dW1Q9bV5OpOv5oZJltVdbN7NB9fjP0y90J+Pa0h85kONhorY/3b9P/HTg0yX9rj+2aBX4qf5Km1edMhhaNnTL0l3wEcM4WpgPcwHABe3V7sYahZe2F7QKxNcLg9Hp8HbhPkju0FqnDRmb9HnCnkfEfJ7n9DKv8DPCUDH1/92XzwDRltn37ReAeaf0XGW4bjdO/AndI8oKpCUkeAvw8cF270D2qjZPkbsAPquqfgL8FHtQWm/5cjPoisHKqbsBzgE/PMu9S6rFLkt8amTb1AZQ7A9e0Vr7nMOzbKYdk+Inz2zE8t59p02/HrW8Kfn1k+p2Aa9p+ftYWyjN6Dj+B4fbZ1nZn4D/a8PQX6HlJcg+GOw9vYPj59/vPsci8VNUPGD449Kwkx0x77LvA9SN9AKcfL1OfH/hl4Ltt/o20YzHJg4AD27ynAU9Lcpf22N5zFO3OzHDcL8JpwK5Jntu2uxPwd8C7Wt1/RlWdxdDCO9Ua/jmGD23CcCxNHYMbgQe34SMYbi3P5kfAkcBzk/x6m/ZJ4LemrlVJ7pnhQz8LluRe2bwf+MEMt5IBvpWh7+p8Pjy5pNe8dv7evapOB17GrXdmxmqW+n6dza9/s5a53dG8GvgThjfSW5x/K/osw/n4naq6pd0h2ZOhdfosFn9efAlY3t7YkeT2Se47xzLbyp0Z6v/DVsaHzGOZc4CpbxR6xpZmHLdtnr4X4Y5JLmjDYejTdUvLdlP+H/DOduvnAlo4rKpNrbXpuNz6gaE/Yeh/tK3MVp8TGU6cLzC8o39ZVX1zC9PvDVBV1yZ5EvDPSX6Doe/R64ELWwDeyHCSbpV6AN9I8gGGW2qXM/Sdm3JsK+c1VfWoNn5hkvOqajQYfYghNF/MsK/OZtoHXmbbt62l9beBTyT5Fre+URiLdivuV4HXZ7h9dxPDc/xK4A1JNnBrX2gYWgb+JslPGG5fT4XN6c/F6DZuSvI84IMZvl3g88BbGKNWjyOB12W43bqJoUXi5QwfxPhQkqcCp7N5S8VZwLpWrzMZvvmCNs99k5zLsK+m3nT8KcP++zpDF5DZAv+fM+zL8xiC27b4NoNXMjzn/8HwAnvglmef0dMZbtP+GPgmQ//bsaiq7z938yIAAAG2SURBVCR5PHBmO7ZHrQbekuEDhVcAzxt57PoMXyO4B0NfWBjOsee2c/jztGtiVV2S5K+ATye5heH8PXoLxXov8NEZjvuF1m3qvHpzkj9leDP1caZ9I8wMXgOcl+TVDP2G35Hk/zAcz1PPwVuBk5KcwxCyt9gy2G7v/grDrefvA29juMV8XrumbmIIyIuxO/DGDF1PbmboC7qGoSHjIoZryefnsZ6lvubtBPxTa6AIQ3/rSXz4aLb6PpOR698cZX4vQx/YSxdYx0m6iKEv7/umTdu9qr6V4UPcCz4vqupHGbrXvKHtm2UMr+eXbHnJbeIUYE2SLzDU7+x5LPMi4D1JXs5wfv/MB1knxV940w4hye6tv9hdGC7sh85ya3NLywb4B+DyqnrdJMsrSRq/DN/DfX5VvX1bl0VL0+6Y/KC92X028KtV9ZS5lhuHHbHlV336WGst2Bn4y/kG3+YFSVa3Zc8H/nESBZQkTU67k/R9hv602vE9hOGu6e0YvsXpeXPMPza2/EqSJKkbO/QH3iRJkqSFMPxKkiSpG4ZfSZIkdcPwK0mSpG4YfiVJktQNw68kSZK68f8Bk01WhGJyRNsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting a histogram of the training labels\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.hist(training_label, bins = 25)\n",
    "from collections import Counter\n",
    "Counter(training_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Convert the training data to lower case. Remove punctuation from the training data. Also remove stop words from the training data using the NLTK package’s English stop word list. In addition to NLTK’s stopwords, are there words speciﬁc to this dataset that may be worthwhile to treat as stop words? What are these words and why would you exclude them? Remove these additional stop words from the training data as well (note: you can also remove this secondary set of stop words after tokenizing. However, keep in mind that this may cause feature alignment issues with your test dataset when you tokenize it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : Other than NLTK's inbuilt stopwords, I removed additional words based on the following criteria:\n",
    "1. President,Presidential,People,American - Since the data is related to the statements made by the democratic candidates for the presidential elections, I removed words that are commonly used in this domain such as president,presidential,people and american which have high occurences and hence they could be treated as stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Converting the training data to lowercase\n",
    "train_data = train_data.str.lower()\n",
    "\n",
    "#removing punctuation from the training data\n",
    "train_data = train_data.str.replace(r\"[#$%&'()*+,-./:;<=>“?’”@[\\]^_`{|}~…]\",'')\n",
    "\n",
    "#removing stop words from the training data\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "train_data = train_data.apply(lambda x :' '.join([word for word in x.split() if word not in stops]) )\n",
    "\n",
    "#removing extra stop words from the test data\n",
    "extra_words = ['presidential','president','american','people']\n",
    "\n",
    "train_data = train_data.apply(lambda x :' '.join([word for word in x.split() if word not in extra_words]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    refuse postpone longer taking climate change leading world taking climate change look united states america theres never single solitary time weve set mind something weve able walking around heads like woe best equipped nation world take longer time postpone get moving theres enormous enormous opportunities get rid donald trump                                                                                                                                                                                                                                                                                                                                           \n",
       "1    got done im one whos ever beat nra one ever beat nra nationally im guy brought brady bill focus became law thats number one number two sandy hook number things happened went cause movement look whats happened mothers organization mothers gun violence weve seen whats happened young marching washington making sure things going change sea change proposals put forward 50 members nra supporting overwhelmingly rest supporting numbers much higher realize ive saying weve saying correct 90 think get assault weapons street period get buybacks get basements point things changed things changed lot whats happening way way beto handles excuse saying beto congressman\n",
       "2    said question speak constitutional scholars fact could say way cant following weapons period cannot sold anymore check constitutional scholars say                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "3    latinos look comparing outrageous number one didnt lock cages didnt separate families didnt things number one number two time came along danderson coopera program one ever done sent legislation desk saying wants find pathway 11 million undocumented united states america done great deal im proud served                                                                                                                                                                                                                                                                                                                                                                      \n",
       "Name: Quote, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing first four rows of the cleaned data\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "train_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Stem/lemmatize your training data using a stemmer/lemmatizer of your choosing. Show a before and after using a few observations and comment on what you see.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : On lemmatizing the data I can see several words are modified to remove their plural endings such as \"latinos\" was modified to \"latino\",\"scholars\" was modified to \"scholar\", \"weapons\" to \"weapon\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five rows of the training data before lemmitizing : \n",
      "0    refuse postpone longer taking climate change leading world taking climate change look united states america theres never single solitary time weve set mind something weve able walking around heads like woe best equipped nation world take longer time postpone get moving theres enormous enormous opportunities get rid donald trump                                                                                                                                                                                                                                                                                                                                           \n",
      "1    got done im one whos ever beat nra one ever beat nra nationally im guy brought brady bill focus became law thats number one number two sandy hook number things happened went cause movement look whats happened mothers organization mothers gun violence weve seen whats happened young marching washington making sure things going change sea change proposals put forward 50 members nra supporting overwhelmingly rest supporting numbers much higher realize ive saying weve saying correct 90 think get assault weapons street period get buybacks get basements point things changed things changed lot whats happening way way beto handles excuse saying beto congressman\n",
      "2    said question speak constitutional scholars fact could say way cant following weapons period cannot sold anymore check constitutional scholars say                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "3    latinos look comparing outrageous number one didnt lock cages didnt separate families didnt things number one number two time came along danderson coopera program one ever done sent legislation desk saying wants find pathway 11 million undocumented united states america done great deal im proud served                                                                                                                                                                                                                                                                                                                                                                      \n",
      "Name: Quote, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Printing the first four rows of the dataset before using the lemmatizer\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(\"First five rows of the training data before lemmitizing : \")\n",
    "print(train_data.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "First five rows of the training data after lemmitizing : \n",
      "0    refuse postpone longer taking climate change leading world taking climate change look united state america there never single solitary time weve set mind something weve able walking around head like woe best equipped nation world take longer time postpone get moving there enormous enormous opportunity get rid donald trump                                                                                                                                                                                                                                                                                                                                   \n",
      "1    got done im one who ever beat nra one ever beat nra nationally im guy brought brady bill focus became law thats number one number two sandy hook number thing happened went cause movement look whats happened mother organization mother gun violence weve seen whats happened young marching washington making sure thing going change sea change proposal put forward 50 member nra supporting overwhelmingly rest supporting number much higher realize ive saying weve saying correct 90 think get assault weapon street period get buyback get basement point thing changed thing changed lot whats happening way way beto handle excuse saying beto congressman\n",
      "2    said question speak constitutional scholar fact could say way cant following weapon period cannot sold anymore check constitutional scholar say                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      "3    latino look comparing outrageous number one didnt lock cage didnt separate family didnt thing number one number two time came along danderson coopera program one ever done sent legislation desk saying want find pathway 11 million undocumented united state america done great deal im proud served                                                                                                                                                                                                                                                                                                                                                               \n",
      "Name: Quote, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Printing the first four rows of the dataset after using the lemmatizer\n",
    "print(\" \")\n",
    "#Using WordNetLemmatizer from nltk.stem\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "train_data = train_data.apply(lambda x :' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "print(\"First five rows of the training data after lemmitizing : \")\n",
    "print(train_data.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Tokenize your training data using unigrams (hint: see sklearn’s CountVectorizer). If you set upper and lower limits on word frequency, what are they? How many unique tokens are in your vocabulary?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : I set a maximum and minimum word document frequency while using CountVectorizer to remove words that occur in less than two documents and words that occur in more than 80% of the document to prevent these commonly used words to skew our predictions when we train our model. After setting the word document frequency limits, I have 2351 unique tokens in my vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique tokens that are in the train data vocabulary are  2351\n"
     ]
    }
   ],
   "source": [
    "#Setting the vectorizer to remove terms that occur in more than 80 percent documents and less than 2 documents\n",
    "vec = CountVectorizer(min_df=2,max_df=0.8)\n",
    "\n",
    "vec.fit(train_data)\n",
    "countsDF =pd.DataFrame()\n",
    "train_counts = vec.transform(train_data)\n",
    "#Creating an array of the training \n",
    "train_counts = train_counts.toarray()\n",
    "countsDF = pd.DataFrame(train_counts,columns=vec.get_feature_names())\n",
    "train_features = vec.get_feature_names()\n",
    "#Print the number of unique tokens in the vocalulary\n",
    "print(\"The number of unique tokens that are in the train data vocabulary are \",len(set(vec.vocabulary_)))\n",
    "\n",
    "#Using tfidf to gain the term frequency only taking unigrams\n",
    "tfidf = TfidfTransformer()\n",
    "train_unigram_tfidf = tfidf.fit_transform(train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Process the test data in a manner identical to the training data. Note that you will need to have the same dimensions for your training and test data. One way in which this can be done is using sklearn’s CountVectorizer is to ﬁt on the training data and transform the test data. Show that the number of features for your training and test data are identical.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : As we can see below, both our training and test dataset have 2351 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the test data to lowercase\n",
    "test_data = test_data.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "#removing punctuation from the test data\n",
    "test_data =test_data.apply(lambda x : x.astype(str).str.replace(r\"[#$%&'()*+,-./:;<=>“?’”@[\\]^_`{|}~…]\",''))\n",
    "\n",
    "#removing stop words from the test data\n",
    "test_data = pd.DataFrame(test_data['Quote'].apply(lambda x :' '.join([word for word in x.split() if word not in stops]) ))\n",
    "\n",
    "\n",
    "#removing extra stop words from the test data\n",
    "extra_words = ['presidential','president','american','people']\n",
    "\n",
    "test_data = pd.DataFrame(test_data['Quote'].apply(lambda x :' '.join([word for word in x.split() if word not in extra_words]) ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique tokens that are in the test data vocabulary are  2351\n"
     ]
    }
   ],
   "source": [
    "#Using WordNetLemmatizer from nltk.stem\n",
    "test_data = pd.DataFrame(test_data['Quote'].apply(lambda x :' '.join([lemmatizer.lemmatize(word) for word in x.split()])))\n",
    "\n",
    "#Setting the vectorizer to remove terms that occur in more than 80% documents and less than 2 documents\n",
    "vec2 = CountVectorizer(min_df=2,max_df=0.8)\n",
    "\n",
    "#Fitting the vectorizer on the training data\n",
    "vec2.fit(train_data)\n",
    "\n",
    "#Transforming the words in the test dara using  thevectorizer\n",
    "counts_test = vec2.transform(test_data['Quote']).toarray()\n",
    "\n",
    "#Print the number of unique tokens in the vocalulary\n",
    "print(\"The number of unique tokens that are in the test data vocabulary are \",len(vec2.vocabulary_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. The primary objective of this problem set is to build classiﬁers to predict who said what. Having the right features are essential for this (and any) prediction task. In addition to the features you were tasked with generating in Part 1, design/build additional features of your choosing. Please note that this process can be iterative in a cycle of designing/adding features and evaluating model performance - this is completely reasonable and you can come back to this question after completing the remainder of Part 2. Describe the features that you ultimately used in your ﬁnal models and articulate your reasoning for including the features that you did. Also describe any feature manipulation/scaling you did and your reasoning for doing so. Ensure your test set has identical features as your training set. Some potential ideas for additional features include bi-/trigrams, topic model weights, TF-IDF weights, sentiments, hand-engineered word co-occurrences (not adding any/all of these is completely ﬁne as well)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : Additional features I have added to my model include TF-IDF weights of each deature to take into account the weights of the features with respect to their occurences in the different documents as well as bigrams to get a better understanding of the context of words.For example, the word country as a unigram may have several interpretations but on adding bigrams, we can see that the word 'country' can have several interpretations when it is placed independently. However when combined with other words the context is easier to understand such as \"country woman\",\"country healthcare\" and \"country immigration\".\n",
    "On adding biagrams as well to our feature set we get the number of featires in our test and training set to be 4749.\n",
    "\n",
    "Further, since our training labels have a high class imbalance, in order to ensure the models do not overfit by predicting the majority classes accurately but failing to predict the minority classes on unobserved data, I used k fold stratified sampling to split my training dataset into a training and validation set to ensure that the propotion of distribution of all the classes are uniform in the training and validation set (I have set the number of folds to 4, hence 1/4th of the number of values of each class is given to the validation set and 3/4th is given to the training set)  so that the model is able to recognize all the classes while training and is able to predict all the labels while testing the model's performance on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of new training features is  4749\n",
      "length of new test features set is  4749\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Including bigrams in our model :\n",
    "tfidf_bigram = TfidfVectorizer(min_df=2,max_df=0.8,ngram_range=(1,2))\n",
    "\n",
    "train_bigram_tfidf= tfidf_bigram.fit_transform(train_data).toarray()\n",
    "print(\"Length of new training features is \",len(tfidf_bigram.vocabulary_))\n",
    "\n",
    "\n",
    "#Fitting our test model \n",
    "tfidf_bigram2 = TfidfVectorizer(min_df=2,max_df=0.8,ngram_range=(1,2))\n",
    "tfidf_bigram2.fit(train_data)\n",
    "test_bigram_tfidf= tfidf_bigram2.transform(test_data['Quote']).toarray()\n",
    "print(\"length of new test features set is \",len(tfidf_bigram2.vocabulary_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set is  Counter({'Warren': 60, 'Biden': 45, 'Buttigieg': 45, 'Sanders': 45, 'Klobuchar': 41, 'Booker': 38, 'Harris': 30, \"O'Rourke\": 25, 'Yang': 24, 'Castro': 17, 'Steyer': 14, 'Gabbard': 12})\n",
      " \n",
      "Class distribution in validation set is  Counter({'Warren': 20, 'Biden': 15, 'Buttigieg': 15, 'Sanders': 15, 'Klobuchar': 14, 'Booker': 12, 'Harris': 10, \"O'Rourke\": 8, 'Yang': 8, 'Castro': 6, 'Steyer': 5, 'Gabbard': 4})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=4)\n",
    "# enumerate the splits and summarize the distributions\n",
    "for train_index, validation_index in kfold.split(train_bigram_tfidf, training_label):\n",
    "    train_X, validation_X = train_bigram_tfidf[train_index], train_bigram_tfidf[validation_index]\n",
    "    train_y, validation_y = training_label[train_index], training_label[validation_index]\n",
    "\n",
    "import collections\n",
    "#We can see there is a 3:1 distribution of the class labels in the training and validation set\n",
    "print(\"Class distribution in training set is \",collections.Counter(train_y))\n",
    "print(\" \")\n",
    "print(\"Class distribution in validation set is \",collections.Counter(validation_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. You will create three diﬀerent models for this problem set: a regularized logistic regression model, a tree-based model (your choice of any tree-based model), and any other model of your choice (regardless of whether it was discussed in class or not). You do not need to implement anything from scratch and can use out-of-the-box models/pipelines. To start, build a regularized logistic regression model. What was your regularization coeﬃcient and how well does this model perform? Are there any classes where it performs particularly well? Are there any classes where it performs particularly poorly? Use graphs/tables where appropriate and contextualize results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : On training the logistic regression model, I chose my regularization coeffient as L2 (ridge regularization). I chose a ridge regularization as it accounts for coefficient constraints for all the features. Further L2 regularization can also estimate coefficients for features even when the number of features are more than the number of observations similar to our case where we have more than 4000 features but only 528 observations in our training set. Further for the 'C' value (inverse of our regularization strength) determines the strength of our lambda .By default the value is one and hence the model would not account for penalities on the features accurately if overfitting occurs.Further if the C value was too small, our lamba  would get too large and may cause underfitting.  Hence i chose a C values of 0.7 to account for the strength of the lambda function used in the ridge regression. \n",
    "Since our training label classes are imbalanced I also chose my class weights to be balanced as it takes into account to give lesser weights for class labels that have higher frequencies.\n",
    "\n",
    "On evaluating the model's performance on the validation set, we get a poor accuracy of 55%.On further examination, I believe that the model performs poorly due to the imbalance amongst the training labels. We can see for classes having higher count in the training set such as \"Warren\",\"Biden\",\"O'Ruke\" the model performs well and we are able to get a higher precision value (the model correctly predicts 71% of the labels tagged as warren,78% of the labels as O'Ruke and 88% of the labels tagged as Biden). However for classes with a lower frequency of values such as \"Gabbard\" the model is only able to predict 33% of the labels tagged as Gabbard. The model also performs particularly poorly in predicting the class labels as \"Booker\" (it only predicts 2 labels accurately from 12 labels ) despite having a class count of 38 values in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is   0.5606060606060606\n"
     ]
    }
   ],
   "source": [
    "#Creating a logistic regression model\n",
    "model_lr=LogisticRegression(solver = 'newton-cg',multi_class='multinomial',class_weight = 'balanced',penalty='l2',max_iter=250,C=0.7).fit(train_X,train_y)\n",
    "predictions = model_lr.predict(validation_X)\n",
    "print(\"Accuracy of the model is  \",accuracy_score(validation_y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for class Biden\n",
      " \n",
      "                predicted:Biden  predicted:not Biden\n",
      "true:Biden      7                8                  \n",
      "true:not Biden  0                0                  \n",
      " \n",
      " \n",
      "Confusion matrix for class Booker\n",
      " \n",
      "                 predicted:Booker  predicted:not Booker\n",
      "true:Booker      4                 8                   \n",
      "true:not Booker  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Buttigieg\n",
      " \n",
      "                    predicted:Buttigieg  predicted:not Buttigieg\n",
      "true:Buttigieg      8                    7                      \n",
      "true:not Buttigieg  0                    0                      \n",
      " \n",
      " \n",
      "Confusion matrix for class Castro\n",
      " \n",
      "                 predicted:Castro  predicted:not Castro\n",
      "true:Castro      2                 4                   \n",
      "true:not Castro  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Gabbard\n",
      " \n",
      "                  predicted:Gabbard  predicted:not Gabbard\n",
      "true:Gabbard      2                  2                    \n",
      "true:not Gabbard  0                  0                    \n",
      " \n",
      " \n",
      "Confusion matrix for class Harris\n",
      " \n",
      "                 predicted:Harris  predicted:not Harris\n",
      "true:Harris      7                 3                   \n",
      "true:not Harris  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Klobuchar\n",
      " \n",
      "                    predicted:Klobuchar  predicted:not Klobuchar\n",
      "true:Klobuchar      8                    6                      \n",
      "true:not Klobuchar  0                    0                      \n",
      " \n",
      " \n",
      "Confusion matrix for class O'Rourke\n",
      " \n",
      "                   predicted:O'Rourke  predicted:not O'Rourke\n",
      "true:O'Rourke      7                   1                     \n",
      "true:not O'Rourke  0                   0                     \n",
      " \n",
      " \n",
      "Confusion matrix for class Sanders\n",
      " \n",
      "                  predicted:Sanders  predicted:not Sanders\n",
      "true:Sanders      9                  6                    \n",
      "true:not Sanders  0                  0                    \n",
      " \n",
      " \n",
      "Confusion matrix for class Steyer\n",
      " \n",
      "                 predicted:Steyer  predicted:not Steyer\n",
      "true:Steyer      5                 0                   \n",
      "true:not Steyer  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Warren\n",
      " \n",
      "                 predicted:Warren  predicted:not Warren\n",
      "true:Warren      12                8                   \n",
      "true:not Warren  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Yang\n",
      " \n",
      "               predicted:Yang  predicted:not Yang\n",
      "true:Yang      3               5                 \n",
      "true:not Yang  0               0                 \n",
      " \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Biden       0.70      0.47      0.56        15\n",
      "      Booker       0.27      0.33      0.30        12\n",
      "   Buttigieg       0.57      0.53      0.55        15\n",
      "      Castro       0.50      0.33      0.40         6\n",
      "     Gabbard       0.33      0.50      0.40         4\n",
      "      Harris       0.37      0.70      0.48        10\n",
      "   Klobuchar       0.67      0.57      0.62        14\n",
      "    O'Rourke       0.78      0.88      0.82         8\n",
      "     Sanders       0.69      0.60      0.64        15\n",
      "      Steyer       0.62      1.00      0.77         5\n",
      "      Warren       0.75      0.60      0.67        20\n",
      "        Yang       0.50      0.38      0.43         8\n",
      "\n",
      "    accuracy                           0.56       132\n",
      "   macro avg       0.56      0.57      0.55       132\n",
      "weighted avg       0.59      0.56      0.56       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating a mukticlass confusion matrix\n",
    "accuracy_score_logistic = []\n",
    "for classes in sorted(list(set(validation_y))):\n",
    "    \n",
    "    class_predictions = []\n",
    "    predicted_values = []\n",
    "    training_labels_class = [label for label in validation_y if label == classes ]\n",
    "    predict_by_class = [class_predictions.append(predictions[i]) for i in range(len(validation_y)) if validation_y[i] == classes ]\n",
    "    \n",
    "    for i in range(len(class_predictions)) :\n",
    "        if class_predictions[i] ==classes:\n",
    "    \n",
    "            predicted_values.append(class_predictions[i])\n",
    "        else:\n",
    "      \n",
    "            predicted_values.append(\"not \" + (classes))\n",
    "                   \n",
    "    print(\"Confusion matrix for class\", classes)\n",
    "    print(\" \")\n",
    "    print(pd.DataFrame(\n",
    "    confusion_matrix(training_labels_class, predicted_values, labels=[classes, \"not \" + (classes)]), \n",
    "    index=['true:' + classes, 'true:' + \"not \" + (classes) ], \n",
    "    columns=['predicted:' + classes, 'predicted:' + \"not \" + (classes)]))\n",
    "\n",
    "    print(\" \")\n",
    "    accuracy_score_logistic.append(accuracy_score(training_labels_class, predicted_values))\n",
    "    print(\" \")\n",
    "    \n",
    "    #Printing classification report of the model\n",
    "report_lr = classification_report(validation_y,predictions)\n",
    "print(report_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Next, build a tree-based model. Which model did you use and why? Are there any classes where it performs particularly well? Are there any classes where it performs particularly poorly? Use graphs/tables where appropriate and contextualize results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a tree based model I selected random forest. This is because a single decision tree is more likely to overfit data since decision trees suffer from high variance.Further, our training data has only 326 observations hence our model would be more suceptible to overfiting if we used a single decision tree. Random forest creates multiple trees by randomly sampling the training dataset thus reducing variance amongst the trees and prevents overfitting of the model.It also runs multiple trees parallely and hence is computationally efficient as well.\n",
    "\n",
    "In order to prevent the random forest model from overfitting the data I have set the depth of my tree as 40 and my number of estimators as 200. On evaluating the performance of our random forest model on the validation set, our model performs very poorly in classifying the validation labels as we get an accuracy of only 37%. The model performs particularly poorly in predicting the validation labels as \"Yang\", \"Steyer\" and \"Booker (predicts none of the labels as yang and Steyer and only 12% of the labels tagged Steyer accurately).The model performs particularly well in predicting the class labels as O'Roukre (predicts 80% of the labels tagged as O'Roukre accurately) .\n",
    "\n",
    "We can see that the random forest model is a low precision low recall model as it fails to fetch all the relevant results from the validation data and it fails to predict the labels accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is  0.4090909090909091\n"
     ]
    }
   ],
   "source": [
    "#Training the random forest classifier\n",
    "model_rf = RandomForestClassifier(n_estimators = 200,min_samples_split= 2, min_samples_leaf= 2, max_depth= 40) \n",
    "model_rf.fit(train_X,train_y)\n",
    "prediction_rf = model_rf.predict(validation_X) \n",
    "print(\"Accuracy of the model is \",accuracy_score(validation_y,prediction_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for class Biden\n",
      " \n",
      "                predicted:Biden  predicted:not Biden\n",
      "true:Biden      7                8                  \n",
      "true:not Biden  0                0                  \n",
      " \n",
      " \n",
      "Confusion matrix for class Booker\n",
      " \n",
      "                 predicted:Booker  predicted:not Booker\n",
      "true:Booker      3                 9                   \n",
      "true:not Booker  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Buttigieg\n",
      " \n",
      "                    predicted:Buttigieg  predicted:not Buttigieg\n",
      "true:Buttigieg      8                    7                      \n",
      "true:not Buttigieg  0                    0                      \n",
      " \n",
      " \n",
      "Confusion matrix for class Castro\n",
      " \n",
      "                 predicted:Castro  predicted:not Castro\n",
      "true:Castro      1                 5                   \n",
      "true:not Castro  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Gabbard\n",
      " \n",
      "                  predicted:Gabbard  predicted:not Gabbard\n",
      "true:Gabbard      1                  3                    \n",
      "true:not Gabbard  0                  0                    \n",
      " \n",
      " \n",
      "Confusion matrix for class Harris\n",
      " \n",
      "                 predicted:Harris  predicted:not Harris\n",
      "true:Harris      3                 7                   \n",
      "true:not Harris  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Klobuchar\n",
      " \n",
      "                    predicted:Klobuchar  predicted:not Klobuchar\n",
      "true:Klobuchar      6                    8                      \n",
      "true:not Klobuchar  0                    0                      \n",
      " \n",
      " \n",
      "Confusion matrix for class O'Rourke\n",
      " \n",
      "                   predicted:O'Rourke  predicted:not O'Rourke\n",
      "true:O'Rourke      4                   4                     \n",
      "true:not O'Rourke  0                   0                     \n",
      " \n",
      " \n",
      "Confusion matrix for class Sanders\n",
      " \n",
      "                  predicted:Sanders  predicted:not Sanders\n",
      "true:Sanders      6                  9                    \n",
      "true:not Sanders  0                  0                    \n",
      " \n",
      " \n",
      "Confusion matrix for class Steyer\n",
      " \n",
      "                 predicted:Steyer  predicted:not Steyer\n",
      "true:Steyer      0                 5                   \n",
      "true:not Steyer  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Warren\n",
      " \n",
      "                 predicted:Warren  predicted:not Warren\n",
      "true:Warren      15                5                   \n",
      "true:not Warren  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Yang\n",
      " \n",
      "               predicted:Yang  predicted:not Yang\n",
      "true:Yang      0               8                 \n",
      "true:not Yang  0               0                 \n",
      " \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Biden       0.64      0.47      0.54        15\n",
      "      Booker       0.18      0.25      0.21        12\n",
      "   Buttigieg       0.42      0.53      0.47        15\n",
      "      Castro       0.33      0.17      0.22         6\n",
      "     Gabbard       0.50      0.25      0.33         4\n",
      "      Harris       0.50      0.30      0.37        10\n",
      "   Klobuchar       0.40      0.43      0.41        14\n",
      "    O'Rourke       0.80      0.50      0.62         8\n",
      "     Sanders       0.46      0.40      0.43        15\n",
      "      Steyer       0.00      0.00      0.00         5\n",
      "      Warren       0.37      0.75      0.49        20\n",
      "        Yang       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.41       132\n",
      "   macro avg       0.38      0.34      0.34       132\n",
      "weighted avg       0.40      0.41      0.39       132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12064\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy_score_rf = []\n",
    "for classes in sorted(list(set(validation_y))):\n",
    "    \n",
    "    class_predictions = []\n",
    "    predicted_values = []\n",
    "    training_labels_class = [label for label in validation_y if label == classes ]\n",
    "    predict_by_class = [class_predictions.append(prediction_rf[i]) for i in range(len(validation_y)) if validation_y[i] == classes ]\n",
    "    \n",
    "    for i in range(len(class_predictions)) :\n",
    "        if class_predictions[i] ==classes:\n",
    "    \n",
    "            predicted_values.append(class_predictions[i])\n",
    "        else:\n",
    "      \n",
    "            predicted_values.append(\"not \" + (classes))\n",
    "                   \n",
    "    print(\"Confusion matrix for class\", classes)\n",
    "    print(\" \")\n",
    "    print(pd.DataFrame(\n",
    "    confusion_matrix(training_labels_class, predicted_values, labels=[classes, \"not \" + (classes)]), \n",
    "    index=['true:' + classes, 'true:' + \"not \" + (classes) ], \n",
    "    columns=['predicted:' + classes, 'predicted:' + \"not \" + (classes)]))\n",
    "\n",
    "    print(\" \")\n",
    "    accuracy_score_rf.append(accuracy_score(training_labels_class, predicted_values))\n",
    "    print(\" \")\n",
    "\n",
    "report_rf = classification_report(validation_y,prediction_rf)\n",
    "print(report_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Next, build any model other than the ones you’ve already built. Which model did you use and why? Did you tune hyperparameters? If so, which ones and how? Are there any classes where it performs particularly well? Are there any classes where it performs particularly poorly? Use graphs/tables where appropriate and contextualize results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : I chose multinomial naive bayes as my third model for multiple reasons. The model does not require much training data to learn(we have only 326 observations in our training set),it performs well for multi class classification and it is suitable for classifying discrete features. These advantages are perfect for the results we are trying to achieve.\n",
    "As naive bayes calculates the conditional probability of each feature given the class label,If the model encounters a word in the test set that was not present in the training set, the model will set the probability of that word as zero. In order to prevent this from occuring, I have set my alpha(smoothning) parameter to 0.85. I obtained this value by doing a five fold randomize search across alpha values ranging from 0.001 to 1 to determine the alpha value that gives the best mean accuracy accross the five folds.\n",
    "\n",
    "Reference : https://stackoverflow.com/questions/33830959/multinomial-naive-bayes-parameter-alpha-setting-scikit-learn\n",
    "\n",
    "On training the multinomial naive bayes model and evaluating the models performance accross the validation set, we get an average accuracy of 61%. We can see that the model performs particularly well across classes when predicting the validation data as \"Castro\" and \"O'Rouke\" (the model predicts 100% of the labels tagged 'Castro' and 'O'Rouke). This shows that the model performs well even for the minority classes (since there were only 17 values of Castro in the training set).The model performs poorly in predicting the labels as Buttigieg as it classifies only 36% of the labels tagged as Buttigieg accurately.\n",
    "\n",
    "On examining the metrics we can see that the Naive Bayes model is a high precision, low recall model indicating it misses to identify all the relevant label values but makes the label predictions on the validation set accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters from Random Search are:\n",
      "{'alpha': 0.5199125334125334}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.4191455696202532\n"
     ]
    }
   ],
   "source": [
    "#building the logistic regression model\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# alpha\n",
    "alpha = [float(x) for x in np.linspace(start = 0.0001, stop = 1, num = 1000000)]\n",
    "\n",
    "\n",
    "\n",
    "#Defining the model we want to tune\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "grid_values = {'alpha': alpha}\n",
    "\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(estimator=MNB,\n",
    "                                   param_distributions=grid_values,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=5\n",
    "                                   )\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(train_X,train_y)\n",
    "\n",
    "\n",
    "\n",
    "print(\"The hyperparameters from Random Search are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is  0.6287878787878788\n"
     ]
    }
   ],
   "source": [
    "#Using multinomial naive bayes model\n",
    "\n",
    "\n",
    "model_NB = MultinomialNB(alpha=0.085).fit(train_X,train_y)\n",
    "predict_NB = model_NB.predict(validation_X)\n",
    "print(\"Accuracy of the model is \",accuracy_score(validation_y,predict_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for class Biden\n",
      " \n",
      "                predicted:Biden  predicted:not Biden\n",
      "true:Biden      8                7                  \n",
      "true:not Biden  0                0                  \n",
      " \n",
      " \n",
      "Confusion matrix for class Booker\n",
      " \n",
      "                 predicted:Booker  predicted:not Booker\n",
      "true:Booker      6                 6                   \n",
      "true:not Booker  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Buttigieg\n",
      " \n",
      "                    predicted:Buttigieg  predicted:not Buttigieg\n",
      "true:Buttigieg      9                    6                      \n",
      "true:not Buttigieg  0                    0                      \n",
      " \n",
      " \n",
      "Confusion matrix for class Castro\n",
      " \n",
      "                 predicted:Castro  predicted:not Castro\n",
      "true:Castro      2                 4                   \n",
      "true:not Castro  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Gabbard\n",
      " \n",
      "                  predicted:Gabbard  predicted:not Gabbard\n",
      "true:Gabbard      2                  2                    \n",
      "true:not Gabbard  0                  0                    \n",
      " \n",
      " \n",
      "Confusion matrix for class Harris\n",
      " \n",
      "                 predicted:Harris  predicted:not Harris\n",
      "true:Harris      7                 3                   \n",
      "true:not Harris  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Klobuchar\n",
      " \n",
      "                    predicted:Klobuchar  predicted:not Klobuchar\n",
      "true:Klobuchar      9                    5                      \n",
      "true:not Klobuchar  0                    0                      \n",
      " \n",
      " \n",
      "Confusion matrix for class O'Rourke\n",
      " \n",
      "                   predicted:O'Rourke  predicted:not O'Rourke\n",
      "true:O'Rourke      7                   1                     \n",
      "true:not O'Rourke  0                   0                     \n",
      " \n",
      " \n",
      "Confusion matrix for class Sanders\n",
      " \n",
      "                  predicted:Sanders  predicted:not Sanders\n",
      "true:Sanders      12                 3                    \n",
      "true:not Sanders  0                  0                    \n",
      " \n",
      " \n",
      "Confusion matrix for class Steyer\n",
      " \n",
      "                 predicted:Steyer  predicted:not Steyer\n",
      "true:Steyer      5                 0                   \n",
      "true:not Steyer  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Warren\n",
      " \n",
      "                 predicted:Warren  predicted:not Warren\n",
      "true:Warren      15                5                   \n",
      "true:not Warren  0                 0                   \n",
      " \n",
      " \n",
      "Confusion matrix for class Yang\n",
      " \n",
      "               predicted:Yang  predicted:not Yang\n",
      "true:Yang      1               7                 \n",
      "true:not Yang  0               0                 \n",
      " \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Biden       0.62      0.53      0.57        15\n",
      "      Booker       0.50      0.50      0.50        12\n",
      "   Buttigieg       0.38      0.60      0.46        15\n",
      "      Castro       1.00      0.33      0.50         6\n",
      "     Gabbard       0.50      0.50      0.50         4\n",
      "      Harris       0.88      0.70      0.78        10\n",
      "   Klobuchar       0.56      0.64      0.60        14\n",
      "    O'Rourke       1.00      0.88      0.93         8\n",
      "     Sanders       0.75      0.80      0.77        15\n",
      "      Steyer       0.83      1.00      0.91         5\n",
      "      Warren       0.68      0.75      0.71        20\n",
      "        Yang       0.50      0.12      0.20         8\n",
      "\n",
      "    accuracy                           0.63       132\n",
      "   macro avg       0.68      0.61      0.62       132\n",
      "weighted avg       0.66      0.63      0.62       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_score_nb = []\n",
    "for classes in sorted(list(set(validation_y))):\n",
    "    \n",
    "    class_predictions = []\n",
    "    predicted_values = []\n",
    "    training_labels_class = [label for label in validation_y if label == classes ]\n",
    "    predict_by_class = [class_predictions.append(predict_NB[i]) for i in range(len(validation_y)) if validation_y[i] == classes ]\n",
    "    \n",
    "    for i in range(len(class_predictions)) :\n",
    "        if class_predictions[i] ==classes:\n",
    "    \n",
    "            predicted_values.append(class_predictions[i])\n",
    "        else:\n",
    "      \n",
    "            predicted_values.append(\"not \" + (classes))\n",
    "                   \n",
    "    print(\"Confusion matrix for class\", classes)\n",
    "    print(\" \")\n",
    "    print(pd.DataFrame(\n",
    "    confusion_matrix(training_labels_class, predicted_values, labels=[classes, \"not \" + (classes)]), \n",
    "    index=['true:' + classes, 'true:' + \"not \" + (classes) ], \n",
    "    columns=['predicted:' + classes, 'predicted:' + \"not \" + (classes)]))\n",
    "\n",
    "    print(\" \")\n",
    "    accuracy_score_nb.append(accuracy_score(training_labels_class, predicted_values))\n",
    "    print(\" \")\n",
    "\n",
    "\n",
    "print(classification_report(validation_y,predict_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Compare the performance of the three classiﬁers you built. Which is the strongest? Which is the weakest? Compare their performance across the diﬀerent classes and use graphs/tables where appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : On comparing the performance of the three classifiers across their accuracy, precision and recall. We can see that for majority of the classes, Naive Bayes gives the highest accuracy except for predicting classes such as \"Harris\" and \"O'ruke\" where the logistic regression model performs better and for predicting classes  zx\"Warren\" where the random forest model performs better. However since our classes are imbalanced, we will need to evaluate the performance of the models based on other parameters such as precision and recall.\n",
    "On comparing the recall values across the three classifiers we can see that the Multinomial Naive Bayes model has a higher recall value across all classes except across the classes \"Yang\" and \"O'rouke' where the logistic regression model is able to identify labels belonging to these classes more accurately. Random forest outperforms the two models only when identifying the labels that belong to the class \"Warren\".This shows that the naive bayes model makes relatively lesser false negative predictions(Indicating that the quote is not said by  particular speaker when it is) compare to the other two models.\n",
    "If we compare the accuracy values accross the three classifiers we can see that for labels that have a higher class distribution such as Biden B,uttigieg and Warren logistic regression predicts the labels of the validation set to be these values with high precision. However ,when we see the classes with a lower distribution such as Steyer, O'ruke, Gabbard and Castro, the Multinomial Naive bayes model is able to predict these labels with a higher precision.\n",
    "\n",
    "Hence on evaluating across all the three metrics with respect to the distribution of the classes, can say that the MultiNomial naive bayes model is the strongest while the Random forest model is the weakest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label frequencies in the validation set:\n",
      "OrderedDict([('Biden', 15), ('Booker', 12), ('Buttigieg', 15), ('Castro', 6), ('Gabbard', 4), ('Harris', 10), ('Klobuchar', 14), (\"O'Rourke\", 8), ('Sanders', 15), ('Steyer', 5), ('Warren', 20), ('Yang', 8)])\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "dict = {}\n",
    "num_iterations=0\n",
    "for i in pd.Series(validation_y).value_counts().index.tolist():\n",
    "    dict[i] = pd.Series(validation_y).value_counts()[num_iterations]\n",
    "    num_iterations = num_iterations + 1\n",
    "    \n",
    "freq = collections.OrderedDict(sorted(dict.items()))\n",
    "\n",
    "print(\"Class label frequencies in the validation set:\")\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy Comparison of the three classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Biden</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Booker</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Buttigieg</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Castro</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gabbard</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Harris</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Klobuchar</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>O'Rourke</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sanders</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Steyer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Warren</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Yang</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  Random Forest  Naive Bayes  Class Distribution\n",
       "Biden      0.466667             0.466667       0.533333     15                \n",
       "Booker     0.333333             0.250000       0.500000     12                \n",
       "Buttigieg  0.533333             0.533333       0.600000     15                \n",
       "Castro     0.333333             0.166667       0.333333     6                 \n",
       "Gabbard    0.500000             0.250000       0.500000     4                 \n",
       "Harris     0.700000             0.300000       0.700000     10                \n",
       "Klobuchar  0.571429             0.428571       0.642857     14                \n",
       "O'Rourke   0.875000             0.500000       0.875000     8                 \n",
       "Sanders    0.600000             0.400000       0.800000     15                \n",
       "Steyer     1.000000             0.000000       1.000000     5                 \n",
       "Warren     0.600000             0.750000       0.750000     20                \n",
       "Yang       0.375000             0.000000       0.125000     8                 "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparing Accuracy of the three classifiers\n",
    "df = pd.DataFrame({'Logistic Regression':accuracy_score_logistic, 'Random Forest': accuracy_score_rf, 'Naive Bayes': accuracy_score_nb, 'Class Distribution' : list(freq.values()) } )\n",
    "df.index = sorted(set(train_y))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12064\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "logistic_precision = precision_recall_fscore_support(validation_y, list(predictions))[0]\n",
    "logistic_recall = precision_recall_fscore_support(validation_y, list(predictions))[1]\n",
    "rf_precision = precision_recall_fscore_support(validation_y, list(prediction_rf))[0]\n",
    "rf_recall= precision_recall_fscore_support(validation_y, list(prediction_rf))[1]\n",
    "nb_precision = precision_recall_fscore_support(validation_y,list(predict_NB))[0]\n",
    "nb_recall = precision_recall_fscore_support(validation_y,list(predict_NB))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall Comparison of the Three classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Biden</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Booker</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Buttigieg</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Castro</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gabbard</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Harris</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Klobuchar</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>O'Rourke</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sanders</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Steyer</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Warren</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Yang</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  Random Forest  Naive Bayes  Class Distribution\n",
       "Biden      0.466667             0.466667       0.533333     15                \n",
       "Booker     0.333333             0.250000       0.500000     12                \n",
       "Buttigieg  0.533333             0.533333       0.600000     15                \n",
       "Castro     0.333333             0.166667       0.333333     6                 \n",
       "Gabbard    0.500000             0.250000       0.500000     4                 \n",
       "Harris     0.700000             0.300000       0.700000     10                \n",
       "Klobuchar  0.571429             0.428571       0.642857     14                \n",
       "O'Rourke   0.875000             0.500000       0.875000     8                 \n",
       "Sanders    0.600000             0.400000       0.800000     15                \n",
       "Steyer     1.000000             0.000000       1.000000     5                 \n",
       "Warren     0.600000             0.750000       0.750000     20                \n",
       "Yang       0.375000             0.000000       0.125000     8                 "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Logistic Regression': logistic_recall, 'Random Forest': rf_recall , 'Naive Bayes': nb_recall, \n",
    "                  'Class Distribution': list(freq.values())} )\n",
    "df.index = sorted(set(validation_y))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision Comparison of the Three classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Biden</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Booker</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Buttigieg</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Castro</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gabbard</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Harris</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Klobuchar</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>O'Rourke</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sanders</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Steyer</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Warren</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Yang</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  Random Forest  Naive Bayes  Class Distribution\n",
       "Biden      0.700000             0.636364       0.615385     15                \n",
       "Booker     0.266667             0.176471       0.500000     12                \n",
       "Buttigieg  0.571429             0.421053       0.375000     15                \n",
       "Castro     0.500000             0.333333       1.000000     6                 \n",
       "Gabbard    0.333333             0.500000       0.500000     4                 \n",
       "Harris     0.368421             0.500000       0.875000     10                \n",
       "Klobuchar  0.666667             0.400000       0.562500     14                \n",
       "O'Rourke   0.777778             0.800000       1.000000     8                 \n",
       "Sanders    0.692308             0.461538       0.750000     15                \n",
       "Steyer     0.625000             0.000000       0.833333     5                 \n",
       "Warren     0.750000             0.365854       0.681818     20                \n",
       "Yang       0.500000             0.000000       0.500000     8                 "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Logistic Regression': logistic_precision, 'Random Forest': rf_precision , 'Naive Bayes': nb_precision, \n",
    "                  'Class Distribution': list(freq.values())} )\n",
    "df.index = sorted(set(validation_y))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Using any of the three models of your choosing, generate labels for the test set. Use only last names in all caps as outputs. In other words, ensure every label is one of the following (note the lack of apostrophes and punctuation): BIDEN, BOOKER, BUTTIGIEG, CASTRO, GABBARD, HARRIS, KLOBUCHAR, OROURKE, SANDERS, STEYER, WARREN, YANG. Save these labels as you will include them in your submission, as detailed at the end of this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our goal is to predict which quote has been said by which democratic speaker,it is importaint for us to predict\n",
    "the right speaker and have lesser false positives (indicating that a particular speaker said a quote that he didn't). Hence\n",
    "I have used the Multinomial naive bayes model to generate labels for the test set as it had the highest precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>MODEL1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>test_1.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test_2.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test_3.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>test_4.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>test_5.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>test_6.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>test_7.txt</td>\n",
       "      <td>GABBARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>test_8.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>test_9.txt</td>\n",
       "      <td>OROURKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>test_10.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>test_11.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>test_12.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>test_13.txt</td>\n",
       "      <td>SANDERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>test_14.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>test_15.txt</td>\n",
       "      <td>BOOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>test_16.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>test_17.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>test_18.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>test_19.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>test_20.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>test_21.txt</td>\n",
       "      <td>BOOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>test_22.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>test_23.txt</td>\n",
       "      <td>BOOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>test_24.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>test_25.txt</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>test_26.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>test_27.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>test_28.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>test_29.txt</td>\n",
       "      <td>SANDERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>test_30.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>test_31.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>test_32.txt</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>test_33.txt</td>\n",
       "      <td>SANDERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>test_34.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>test_35.txt</td>\n",
       "      <td>BOOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>test_36.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>test_37.txt</td>\n",
       "      <td>BOOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>test_38.txt</td>\n",
       "      <td>BOOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>test_39.txt</td>\n",
       "      <td>BOOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>test_40.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>test_41.txt</td>\n",
       "      <td>SANDERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>test_42.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>test_43.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>test_44.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>test_45.txt</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>test_46.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>test_47.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>test_48.txt</td>\n",
       "      <td>OROURKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>test_49.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>test_50.txt</td>\n",
       "      <td>BOOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>test_51.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>test_52.txt</td>\n",
       "      <td>SANDERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>test_53.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>test_54.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>test_55.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>test_56.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>test_57.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>test_58.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>test_59.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>test_60.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>test_61.txt</td>\n",
       "      <td>GABBARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>test_62.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>test_63.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>test_64.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>test_65.txt</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>test_66.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>test_67.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>test_68.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>test_69.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>test_70.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>test_71.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>test_72.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>test_73.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>test_74.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>test_75.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>test_76.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>test_77.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>test_78.txt</td>\n",
       "      <td>GABBARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>test_79.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>test_80.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>test_81.txt</td>\n",
       "      <td>BOOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>test_82.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>test_83.txt</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>test_84.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>test_85.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>test_86.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>test_87.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>test_88.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>test_89.txt</td>\n",
       "      <td>BOOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>test_90.txt</td>\n",
       "      <td>SANDERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>test_91.txt</td>\n",
       "      <td>SANDERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>test_92.txt</td>\n",
       "      <td>YANG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>test_93.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>test_94.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>test_95.txt</td>\n",
       "      <td>SANDERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>test_96.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>test_97.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>test_98.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>test_99.txt</td>\n",
       "      <td>OROURKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>test_100.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>test_101.txt</td>\n",
       "      <td>CASTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>test_102.txt</td>\n",
       "      <td>BOOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>test_103.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>test_104.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>test_105.txt</td>\n",
       "      <td>WARREN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>test_106.txt</td>\n",
       "      <td>BUTTIGIEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>test_107.txt</td>\n",
       "      <td>GABBARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>test_108.txt</td>\n",
       "      <td>BOOKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>test_109.txt</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>test_110.txt</td>\n",
       "      <td>KLOBUCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>test_111.txt</td>\n",
       "      <td>BIDEN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         FILENAME     MODEL1\n",
       "0    test_1.txt    WARREN   \n",
       "1    test_2.txt    WARREN   \n",
       "2    test_3.txt    BIDEN    \n",
       "3    test_4.txt    WARREN   \n",
       "4    test_5.txt    BUTTIGIEG\n",
       "5    test_6.txt    WARREN   \n",
       "6    test_7.txt    GABBARD  \n",
       "7    test_8.txt    BUTTIGIEG\n",
       "8    test_9.txt    OROURKE  \n",
       "9    test_10.txt   WARREN   \n",
       "10   test_11.txt   KLOBUCHAR\n",
       "11   test_12.txt   KLOBUCHAR\n",
       "12   test_13.txt   SANDERS  \n",
       "13   test_14.txt   BIDEN    \n",
       "14   test_15.txt   BOOKER   \n",
       "15   test_16.txt   KLOBUCHAR\n",
       "16   test_17.txt   WARREN   \n",
       "17   test_18.txt   WARREN   \n",
       "18   test_19.txt   BIDEN    \n",
       "19   test_20.txt   WARREN   \n",
       "20   test_21.txt   BOOKER   \n",
       "21   test_22.txt   WARREN   \n",
       "22   test_23.txt   BOOKER   \n",
       "23   test_24.txt   WARREN   \n",
       "24   test_25.txt   HARRIS   \n",
       "25   test_26.txt   BUTTIGIEG\n",
       "26   test_27.txt   BUTTIGIEG\n",
       "27   test_28.txt   BIDEN    \n",
       "28   test_29.txt   SANDERS  \n",
       "29   test_30.txt   WARREN   \n",
       "30   test_31.txt   WARREN   \n",
       "31   test_32.txt   HARRIS   \n",
       "32   test_33.txt   SANDERS  \n",
       "33   test_34.txt   BUTTIGIEG\n",
       "34   test_35.txt   BOOKER   \n",
       "35   test_36.txt   BUTTIGIEG\n",
       "36   test_37.txt   BOOKER   \n",
       "37   test_38.txt   BOOKER   \n",
       "38   test_39.txt   BOOKER   \n",
       "39   test_40.txt   WARREN   \n",
       "40   test_41.txt   SANDERS  \n",
       "41   test_42.txt   KLOBUCHAR\n",
       "42   test_43.txt   BIDEN    \n",
       "43   test_44.txt   WARREN   \n",
       "44   test_45.txt   HARRIS   \n",
       "45   test_46.txt   KLOBUCHAR\n",
       "46   test_47.txt   BIDEN    \n",
       "47   test_48.txt   OROURKE  \n",
       "48   test_49.txt   BUTTIGIEG\n",
       "49   test_50.txt   BOOKER   \n",
       "50   test_51.txt   KLOBUCHAR\n",
       "51   test_52.txt   SANDERS  \n",
       "52   test_53.txt   WARREN   \n",
       "53   test_54.txt   KLOBUCHAR\n",
       "54   test_55.txt   BUTTIGIEG\n",
       "55   test_56.txt   WARREN   \n",
       "56   test_57.txt   BUTTIGIEG\n",
       "57   test_58.txt   BIDEN    \n",
       "58   test_59.txt   BUTTIGIEG\n",
       "59   test_60.txt   BIDEN    \n",
       "60   test_61.txt   GABBARD  \n",
       "61   test_62.txt   BUTTIGIEG\n",
       "62   test_63.txt   KLOBUCHAR\n",
       "63   test_64.txt   BUTTIGIEG\n",
       "64   test_65.txt   HARRIS   \n",
       "65   test_66.txt   BUTTIGIEG\n",
       "66   test_67.txt   KLOBUCHAR\n",
       "67   test_68.txt   WARREN   \n",
       "68   test_69.txt   KLOBUCHAR\n",
       "69   test_70.txt   WARREN   \n",
       "70   test_71.txt   BUTTIGIEG\n",
       "71   test_72.txt   BIDEN    \n",
       "72   test_73.txt   WARREN   \n",
       "73   test_74.txt   BIDEN    \n",
       "74   test_75.txt   BUTTIGIEG\n",
       "75   test_76.txt   BIDEN    \n",
       "76   test_77.txt   KLOBUCHAR\n",
       "77   test_78.txt   GABBARD  \n",
       "78   test_79.txt   BUTTIGIEG\n",
       "79   test_80.txt   KLOBUCHAR\n",
       "80   test_81.txt   BOOKER   \n",
       "81   test_82.txt   WARREN   \n",
       "82   test_83.txt   HARRIS   \n",
       "83   test_84.txt   BUTTIGIEG\n",
       "84   test_85.txt   WARREN   \n",
       "85   test_86.txt   WARREN   \n",
       "86   test_87.txt   WARREN   \n",
       "87   test_88.txt   WARREN   \n",
       "88   test_89.txt   BOOKER   \n",
       "89   test_90.txt   SANDERS  \n",
       "90   test_91.txt   SANDERS  \n",
       "91   test_92.txt   YANG     \n",
       "92   test_93.txt   WARREN   \n",
       "93   test_94.txt   WARREN   \n",
       "94   test_95.txt   SANDERS  \n",
       "95   test_96.txt   WARREN   \n",
       "96   test_97.txt   KLOBUCHAR\n",
       "97   test_98.txt   BIDEN    \n",
       "98   test_99.txt   OROURKE  \n",
       "99   test_100.txt  KLOBUCHAR\n",
       "100  test_101.txt  CASTRO   \n",
       "101  test_102.txt  BOOKER   \n",
       "102  test_103.txt  KLOBUCHAR\n",
       "103  test_104.txt  WARREN   \n",
       "104  test_105.txt  WARREN   \n",
       "105  test_106.txt  BUTTIGIEG\n",
       "106  test_107.txt  GABBARD  \n",
       "107  test_108.txt  BOOKER   \n",
       "108  test_109.txt  HARRIS   \n",
       "109  test_110.txt  KLOBUCHAR\n",
       "110  test_111.txt  BIDEN    "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the multinomial naive bayes model to generate labels for our test set\n",
    "model_TestNB = MultinomialNB(alpha=0.085).fit(train_X,train_y)\n",
    "predict_NBTest = model_TestNB.predict(test_bigram_tfidf)\n",
    "\n",
    "#Storing the results copy\n",
    "predict_NBTest_Copy = predict_NBTest\n",
    "\n",
    "#Converting the results to upper case\n",
    "predict_NBTest=[x.upper() for x in predict_NBTest]\n",
    "\n",
    "\n",
    "#creating a dataframe to store the results\n",
    "result_Df=pd.DataFrame()\n",
    "\n",
    "result_Df['MODEL1'] = predict_NBTest\n",
    "\n",
    "#Trimming the spaces \n",
    "result_Df['MODEL1'] =result_Df['MODEL1'].apply(lambda x : x.strip())\n",
    "\n",
    "nameList = [\"test_\"+str(file+1) + \".txt\" for file in range(len(result_Df))]\n",
    "\n",
    "result_Df['FILENAME'] = nameList\n",
    "\n",
    "#Removing punchuations from the model results\n",
    "\n",
    "result_Df['MODEL1'] =result_Df['MODEL1'].apply(lambda x : x.replace(r\"'\",''))\n",
    "\n",
    "#Rearranging the dataframe\n",
    "result_Df=result_Df[['FILENAME','MODEL1']]\n",
    "\n",
    "#Displaying the current details in the results\n",
    "result_Df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Semi-Supervised Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. For this part, we will implement a semi-supervised learning process. As a ﬁrst step, select which of the classiﬁers from part 2 you will use. You want a classiﬁer that outputs class probabilities (i.e. predict proba in sklearn). We will be training and re-training this classiﬁer 10 more times so you also want to use a model that does not take long to train. State which model you chose and your thought process for choosing it versus the other models. You may want to copy this model to another variable so you can refer to it in its current form later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : For this part I have chosen the Multinomial Naive Bayes model. This is because the model takes lesser time to train as required further.In addition we can see that since our dataset has high imbalance amongst the classes, the Naive bayes model had a high precision value even for the minority classes indicating it performs well on imbalanced classes as well in comparision to the logistic regression and random forest model whose performance falters when classifying labels of minority classes. Also, since our goal is to classify the speakers accurately based on the quotes, high precision an importaint factor we want to achieve which we saw was the best when using the Naive bayes models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the multinomial naive bayes model\n",
    "#Copying model to another variable\n",
    "accuracy_list=[]\n",
    "model_TestNB2 = model_TestNB\n",
    "\n",
    "#Appending the accuracy score when appending 0% of the test data\n",
    "accuracy_list.append(accuracy_score(validation_y,model_TestNB2.predict(validation_X)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. The process for semi-supervised learning will involve iteratively adding subsets of our test dataset to our training dataset. To start, using the model you selected in QXX, predict label probabilities on the test set. Take the top 10% of test instances which have the highest probability of having the correct labels (i.e. the highest probabilities of belonging to any class). Add your predicted labels to this 10% and then add it to your training data. Retrain your model on this updated training set. How does the performance on the original training dataset compare between this model and the one you trained in Part 2?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: On adding 10% of the top predicted probabilities of the test set to the training data, the models accuracy remains the same (62%). However, if we compare the precision values obtained now in comparision to part 2, we can see that the model's precisions across all classes have actually increased or remained the same. Since our training set was relatively small in the previous part (326 values) our model could have been overfitting the data leading to a higher accuracy rate hence when supplied with more data to train, the models accuracy has lowered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting probabilities of the test set\n",
    "model_TestNB_probabilities = model_TestNB2.predict_proba(test_bigram_tfidf)\n",
    "\n",
    "#Creating a dataframe with the predicted probabilities\n",
    "probability_df = pd.DataFrame(data=model_TestNB_probabilities)\n",
    "\n",
    "#Finding highest probability of each row and storing it in a new column\n",
    "probability_df['highest_prob'] = probability_df.max(axis=1)\n",
    "probability_df=probability_df.reset_index()\n",
    "\n",
    "#Sorting the probabilities in ascending order\n",
    "probability_df=probability_df.sort_values(by=['highest_prob'],ascending=False)\n",
    "\n",
    "#Storing the top 10% probabilities\n",
    "top_10=probability_df[:int(len(probability_df)/10)]\n",
    "\n",
    "#Creating a copy of the training dataset\n",
    "new_train_X = train_X\n",
    "new_train_y = train_y\n",
    "\n",
    "#Iterating through each row of the top 10% and appending the test features and preicted labels it to our training set\n",
    "for index,row in top_10.iterrows():\n",
    "    new_train_X=np.vstack([new_train_X,test_bigram_tfidf[index]])\n",
    "    new_train_y=np.append(new_train_y,predict_NBTest_Copy[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Biden       0.73      0.53      0.62        15\n",
      "      Booker       0.55      0.50      0.52        12\n",
      "   Buttigieg       0.38      0.67      0.49        15\n",
      "      Castro       1.00      0.33      0.50         6\n",
      "     Gabbard       0.50      0.50      0.50         4\n",
      "      Harris       0.88      0.70      0.78        10\n",
      "   Klobuchar       0.56      0.64      0.60        14\n",
      "    O'Rourke       1.00      0.88      0.93         8\n",
      "     Sanders       0.71      0.80      0.75        15\n",
      "      Steyer       0.80      0.80      0.80         5\n",
      "      Warren       0.61      0.70      0.65        20\n",
      "        Yang       0.50      0.12      0.20         8\n",
      "\n",
      "    accuracy                           0.62       132\n",
      "   macro avg       0.68      0.60      0.61       132\n",
      "weighted avg       0.66      0.62      0.62       132\n",
      "\n",
      "Accuracy of the new model is  0.6212121212121212\n"
     ]
    }
   ],
   "source": [
    "#Retraining the model taking new train data\n",
    "updated_Model=model_TestNB2.fit(new_train_X,new_train_y)\n",
    "#Evaluating the model's performance on the validation set\n",
    "predicted_model_TestNB2 = updated_Model.predict(validation_X)\n",
    "print(classification_report(validation_y,predicted_model_TestNB2))\n",
    "print(\"Accuracy of the new model is \",accuracy_score(validation_y,predicted_model_TestNB2))\n",
    "#Appending the accuracy to the accuracy list\n",
    "accuracy_list.append(accuracy_score(validation_y,predicted_model_TestNB2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Now, repeat the process above 9 more times, each time adding an additional 10% of the test data for which the labels have the highest probability (note that this may result in diﬀerent test observations being included from one iteration to the next). After each iteration, note the performance on the original training data set. Generate a plot which shows the percentage of the test dataset used on the X-axis and the classiﬁcation accuracy on the original training dataset on the Y-axis. There should be 11 points for this plot, ranging from X = 0% to X = 100%, inclusive. What does the plot look like? Comment on what you see. (Note: this type of semi-supervised learning can very much be hit-or-miss. This type of learning doesn’t always yield beneﬁts).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer : On plotting the graph for the accuracy of the model and the % percentage of test data added, I can see that my model's accuracy  decreases in comparison to when there was no additional data added to the training set. I believe this occurs as semi-supervised learning relies on several assumptions that are external to our classifier such as the neighboring point have the same label.Only if such assumptions are met is the model able to perform well on addition of test data.Further,since semi supervised learning is a self learning approach even a single outlier could affect the models predictions due to which the models accuracy might be decreasing.\n",
    "\n",
    "Reference : https://www.infoworld.com/article/3434618/semi-supervised-learning-explained.html\n",
    "         https://www.researchgate.net/post/How_reliable_are_the_SemiSupervised_learning_algorithms_that_are_gaining_in_popularity_especially_in_fields_where_labeled_data_is_scarce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the test features in a copy\n",
    "test_X = test_bigram_tfidf.copy()\n",
    "\n",
    "#Iterating through 9 times adding 10%(11rows) of the test features each time\n",
    "for i in range(9):\n",
    "    #Removing the top 10 porbability features from the test set copy\n",
    "    test_X = np.delete(test_X,top_10.index,axis=0)\n",
    "    \n",
    "    #Predicting probabilities of the test set with the updated rows\n",
    "    model_TestNB_probabilities = updated_Model.predict_proba(test_X)\n",
    "    \n",
    "    #Creating a dataframe of the new probabilities\n",
    "    probability_df = pd.DataFrame(data=model_TestNB_probabilities)\n",
    "    probability_df['highest_prob'] = probability_df.max(axis=1)\n",
    "    probability_df = probability_df.reset_index()                                                    \n",
    "                                                        \n",
    "    probability_df=probability_df.sort_values(by=['highest_prob'],ascending=False)\n",
    "    \n",
    "    #Selecting the top 10% (11 rows) of highest probability features from the test set\n",
    "    top_10 = probability_df.iloc[:11,:]\n",
    "    \n",
    "    #Iterating through each row/index \n",
    "    for index,row in top_10.iterrows():\n",
    "        new_train_X=np.vstack([new_train_X,test_X[index]])\n",
    "        new_train_y=np.append(new_train_y,predict_NBTest_Copy[index])\n",
    "    updated_Model=updated_Model.fit(new_train_X,new_train_y)\n",
    "    prediction_updated = updated_Model.predict(validation_X)\n",
    "    accuracy_list.append(accuracy_score(validation_y,prediction_updated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "list_percentage = list(range(0,110,10))\n",
    "plt.plot(list_percentage,accuracy_list)\n",
    "plt.xticks(list_percentage)\n",
    "plt.ylabel(\"Accuracy on validation set\")\n",
    "plt.xlabel(\"% of test features added to training data\")\n",
    "plt.title(\"% of Test features added vs Accuracy of model on validation set \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Using the model that is trained on the entirety of the training data and 100% of the test data (labeled by you), generate a ﬁnal set of labels for the test data. Be sure to only use last names\n",
    "in all caps for the labels, as you did in Question 12. Include these in your submission per the instructions below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating final set of labels on the test data\n",
    "\n",
    "updatedModel = MultinomialNB(alpha=0.085).fit(new_train_X,new_train_y)\n",
    "finalPredictions = updatedModel.predict(test_bigram_tfidf)\n",
    "\n",
    "\n",
    "#Converting the results to upper case\n",
    "finalPredictions=[x.upper() for x in finalPredictions]\n",
    "\n",
    "#Appending the results to the final dataframe\n",
    "result_Df['MODEL2'] = finalPredictions\n",
    "\n",
    "\n",
    "\n",
    "#Removing punchuations from the model results\n",
    "\n",
    "result_Df['MODEL2'] =result_Df['MODEL2'].apply(lambda x : x.replace(r\"'\",''))\n",
    "\n",
    "#Rearranging the dataframe\n",
    "result_Df=result_Df[['FILENAME','MODEL1','MODEL2']]\n",
    "\n",
    "#Displaying the final results of the dataframe\n",
    "result_Df \n",
    "\n",
    "#Writing the results to a text file\n",
    "np.savetxt('results.txt', result_Df.values, delimiter=\"\\t\\t\", fmt=\"%-12s\", comments='', header=\"FILENAME\\t\\tMODEL1\\t\\t\\tMODEL2\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
